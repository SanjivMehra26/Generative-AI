{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNn2bQL46x1+YUpK3GY6M5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjivMehra26/Generative-AI/blob/main/Coding_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-sml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqkjIbPK2hK_",
        "outputId": "a9caa025-1b56-4e99-b67f-d3b5cbb94786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-sml: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-at-Ivk21y0",
        "outputId": "715de1a6-6985-4afc-cae5-f124a46de25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 11 10:53:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "\n",
        "def processname(name):\n",
        "  pdb.set_trace() # c for comtinue, l from seeing the line , n for next line\n",
        "  when = \"today\"\n",
        "  print(name,'is using google colab',when)\n",
        "\n",
        "processname('javier')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzV3ZMpd27-5",
        "outputId": "7cc74a5a-2e9e-48d9-b853-d6e74b9e1aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[0;32m<ipython-input-15-fb74a2c99318>\u001b[0m(5)\u001b[0;36mprocessname\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mprocessname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      4 \u001b[0;31m  \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# c for comtinue, l from seeing the line , n for next line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m  \u001b[0mwhen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"today\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      6 \u001b[0;31m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'is using google colab'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n",
            "javier is using google colab today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries\n",
        "\n",
        "import torch, pdb\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plty"
      ],
      "metadata": {
        "id": "djGIk8XF4Y_y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization function\n",
        "def show(tensor, ch=1, size=(28,28),num=16):\n",
        "  #tensor: 128 (Batch size) * 784 (28*28)\n",
        "  tensor.detach().cpu().view(-1,ch,*size) #128*1*28*28\n",
        "  grid = make_grid(data[:num],nrow=4).permute(1,2,0)\n",
        "  plt.imshow(grid)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "t1WTEdIh80rF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup of the main parameters and hyperparameters\n",
        "\n",
        "epochs = 500\n",
        "cur_step = 0\n",
        "info_step = 300\n",
        "mean_gen_loss = 0\n",
        "mean_disc_loss = 0\n",
        "\n",
        "z_dim = 64\n",
        "lr = 0.00001\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "bs = 128\n",
        "device = 'cuda'\n",
        "\n",
        "dataloader = DataLoader(MNIST('.',download=True,transform=transforms.ToTensor()),shuffle=True,batch_size=bs)\n",
        "\n",
        "# number if steps = 60000 / 128 =\n",
        "# 60K number of image MNIST has in package"
      ],
      "metadata": {
        "id": "mrDwXfmHAb8e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# declare our models\n",
        "\n",
        "# Generator\n",
        "\n",
        "def genBlock(inp,out):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(inp,out),\n",
        "      nn.BatchNorm1d(out),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "\n",
        "  class Generator(nn.Module):\n",
        "    def __init__(self,z_dim=64,i_dim=784,h_dim=128):\n",
        "      super().__init__()\n",
        "      self.gen = nn.Sequential(\n",
        "          genBlock(z_dim,h_dim),\n",
        "          genBlock(h_dim,h_dim*2),\n",
        "          genBlock(h_dim*2,h_dim*4),\n",
        "          genBlock(h_dim*4,h_dim*8),\n",
        "          nn.Linear(h_dim*8,i_dim),\n",
        "          nn.sigmoid(),\n",
        "\n",
        "      )\n",
        "\n",
        "      def forward(self,noise):\n",
        "        return self.gen(noise)\n",
        "\n",
        "def gen_noise(number,z_dim):\n",
        "  return torch.randn(number,z_dim).to(device)"
      ],
      "metadata": {
        "id": "5cJAyyiXDTKp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Discriminator\n",
        "\n",
        "def discBlock(inp,out):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(inp,out),\n",
        "      nn.LeakyReLU(0.2)\n",
        "  )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,i_dim=784,h_dim=256):\n",
        "    super().__init__()\n",
        "    self.disc=nn.Sequential(\n",
        "        discBlock(i_dim,h_dim*4),\n",
        "        discBlock(h_dim*4,h_dim*2),\n",
        "        discBlock(i_dim*2,h_dim),\n",
        "        nn.Linear(h_dim,1)\n",
        "    )\n",
        "\n",
        "    def forward(self,image):\n",
        "        return self.disc(image)"
      ],
      "metadata": {
        "id": "15e6g0v-GVGt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lR8OH1m2HppL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}